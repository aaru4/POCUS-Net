{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTrWBsEt8zJbmmawaT9QIn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import os\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'"
      ],
      "metadata": {
        "id": "XnEm6iKE-_8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the path to the zip file and the directory where you want to extract the contents\n",
        "zip_file_path = '/content/diameterAnnotations.zip'\n",
        "extracted_dir = '/content/extractions'\n",
        "\n",
        "# Create the target directory if it doesn't exist\n",
        "os.makedirs(extracted_dir, exist_ok=True)\n",
        "\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Extract all the contents to the specified directory\n",
        "    zip_ref.extractall(extracted_dir)\n",
        "\n",
        "print(f\"Contents extracted to: {extracted_dir}\")"
      ],
      "metadata": {
        "id": "2497y-ZkzGDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2006457-079f-46c2-93b0-a28a6db93487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents extracted to: /content/extractions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow for displaying images in Colab\n",
        "\n",
        "# Function to parse the XML file and get annotations\n",
        "def parse_annotations(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    annotations = []\n",
        "\n",
        "    for image_elem in root.findall('image'):\n",
        "        image_name = image_elem.get('name')\n",
        "        image_annotations = []\n",
        "\n",
        "        for polyline_elem in image_elem.findall('polyline'):\n",
        "            label = polyline_elem.get('label')\n",
        "            points_str = polyline_elem.get('points')\n",
        "            points = [tuple(map(float, point.split(','))) for point in points_str.split(';')]\n",
        "\n",
        "            image_annotations.append({\n",
        "                'label': label,\n",
        "                'points': points\n",
        "            })\n",
        "\n",
        "        annotations.append({\n",
        "            'image_name': image_name,\n",
        "            'annotations': image_annotations\n",
        "        })\n",
        "\n",
        "    return annotations\n",
        "\n",
        "# Function to print annotated images\n",
        "def print_annotated_images(annotations, images_dir):\n",
        "    for annotation in annotations:\n",
        "        image_name = annotation['image_name']\n",
        "        image_path = os.path.join(images_dir, image_name)\n",
        "\n",
        "        # Load the image using OpenCV\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        if image is None:\n",
        "            print(f\"Error loading image: {image_path}\")\n",
        "            continue\n",
        "\n",
        "        for polyline in annotation['annotations']:\n",
        "            label = polyline['label']\n",
        "            points = np.array(polyline['points'], dtype=np.int32)  # Convert points to int32\n",
        "\n",
        "            # Draw polyline on the image\n",
        "            cv2.polylines(image, [points], isClosed=True, color=(0, 255, 0), thickness=2)\n",
        "\n",
        "        # Display the image with annotations\n",
        "        cv2_imshow(image)\n",
        "\n",
        "\n",
        "xml_file_path = '/content/extractions/annotations.xml'\n",
        "images_dir = '/content/images'\n",
        "\n",
        "annotations = parse_annotations(xml_file_path)\n",
        "print_annotated_images(annotations, images_dir)"
      ],
      "metadata": {
        "id": "e7BrPK53HD-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow opencv-python numpy yolov3-tf2\n",
        "!pip install yolov3-tf2==0.3.0"
      ],
      "metadata": {
        "id": "7JPUgzj_J3xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "segment diameters"
      ],
      "metadata": {
        "id": "ebwqrL5cSL4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam  # Import Adam optimizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Function to parse the XML file and get annotations\n",
        "def parse_annotations(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    annotations = []\n",
        "\n",
        "    for image_elem in root.findall('image'):\n",
        "        image_name = image_elem.get('name')\n",
        "        image_annotations = []\n",
        "\n",
        "        for polyline_elem in image_elem.findall('polyline'):\n",
        "            label = polyline_elem.get('label')\n",
        "            points_str = polyline_elem.get('points')\n",
        "            points = [tuple(map(float, point.split(','))) for point in points_str.split(';')]\n",
        "\n",
        "            image_annotations.append({\n",
        "                'label': label,\n",
        "                'points': points\n",
        "            })\n",
        "\n",
        "        annotations.append({\n",
        "            'image_name': image_name,\n",
        "            'annotations': image_annotations\n",
        "        })\n",
        "\n",
        "    return annotations\n",
        "\n",
        "# Load annotations\n",
        "xml_file_path = '/content/extractions/annotations.xml'\n",
        "images_dir = '/content/images'\n",
        "\n",
        "annotations = parse_annotations(xml_file_path)\n",
        "\n",
        "# Prepare data for training\n",
        "X = []  # Images\n",
        "labels = []  # List of Labels\n",
        "\n",
        "for annotation in annotations:\n",
        "    image_name = annotation['image_name']\n",
        "    image_path = os.path.join(images_dir, image_name)\n",
        "\n",
        "    # Load the image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is None:\n",
        "        print(f\"Error loading image: {image_path}\")\n",
        "        continue\n",
        "\n",
        "    for polyline in annotation['annotations']:\n",
        "        label_value = polyline['label']  # Use a different variable name\n",
        "        points = np.array(polyline['points'], dtype=np.int32)\n",
        "\n",
        "        # Extract the region of interest (ROI) from the image based on the points\n",
        "        x, y, w, h = cv2.boundingRect(points)\n",
        "        roi = image[y:y+h, x:x+w]\n",
        "\n",
        "        # Resize the ROI to a fixed size\n",
        "        roi = cv2.resize(roi, (224, 224))\n",
        "\n",
        "        X.append(roi)\n",
        "        labels.append(label_value)  # Append the label value\n",
        "\n",
        "X = np.array(X)\n",
        "labels = np.array(labels)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN model with Adam optimizer and a learning rate of 0.001\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(len(label_encoder.classes_), activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Set the learning rate for the Adam optimizer\n",
        "adam_optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=28, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save the trained model\n",
        "model.save('diameter_detection_model.h5')\n",
        "\n",
        "# Optionally, save the label encoder for later use\n",
        "import joblib\n",
        "joblib.dump(label_encoder, 'label_encoder.joblib')\n"
      ],
      "metadata": {
        "id": "A0dsf5W2KKg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdqe8zlBhSsc",
        "outputId": "5b790e58-5fa1-4296-ab6c-0155d94e9459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use your ultrasound's scale to determine the length of the AP and CC diameters above. Type proceed when complete.  proceed\n",
            "Enter patient age: 23\n",
            "Measure the anteroposterior diameter of the antrum and enter value: 4\n",
            "Measure the craniocaudal diameter of the antrum and enter value: .6\n",
            "Estimated Gastric Volume: 26.965307237600467\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "access_diameters = input(\"Use your ultrasound's scale to determine the length of the AP and CC diameters above. Type proceed when complete.  \").lower()\n",
        "\n",
        "def calculate_gastric_volume():\n",
        "    # Prompt the user for input\n",
        "\n",
        "    age_input = input(\"Enter patient age: \")\n",
        "    ap_diameter_input = input(\"Measure the anteroposterior diameter of the antrum and enter value: \")\n",
        "    cc_diameter_input = input(\"Measure the craniocaudal diameter of the antrum and enter value: \")\n",
        "\n",
        "    try:\n",
        "        # Convert user inputs to float\n",
        "        age = float(age_input)\n",
        "        ap_diameter = float(ap_diameter_input)\n",
        "        cc_diameter = float(cc_diameter_input)\n",
        "\n",
        "        # Calculate gastric volume\n",
        "        gastric_volume = 27 + (15.6 * (math.pi * ap_diameter * cc_diameter / 4)) - (1.28 * age)\n",
        "\n",
        "        return gastric_volume\n",
        "    except ValueError:\n",
        "        print(\"Invalid input. Please enter numeric values.\")\n",
        "        return None\n",
        "\n",
        "# Call the function to calculate gastric volume\n",
        "if access_diameters:\n",
        "  result = calculate_gastric_volume()\n",
        "  if result is not None:\n",
        "    print(\"Estimated Gastric Volume:\", result)\n",
        "\n",
        "\n"
      ]
    }
  ]
}